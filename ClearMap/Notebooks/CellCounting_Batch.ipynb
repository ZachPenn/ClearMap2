{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['DISPLAY'] = ':999'\n",
    "sys.path.append('/home/zachpen87/clearmap/ClearMap2/')\n",
    "\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import dask.array as da\n",
    "import scipy.ndimage as ndimage\n",
    "import skimage\n",
    "from ClearMap.Environment import * \n",
    "import ClearMap.ImageProcessing.H5 as H5img\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify List of Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_01/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_02/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_03/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_04/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_05/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_06/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_07/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_08/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_09/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_10/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_11/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_12/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_13/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_14/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_15/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_16/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_17/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_18/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_19/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_20/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_21/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_22/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_23/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_24/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_25/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_26/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_27/',\n",
    "    '/home/zachpen87/clearmap/data/SEFL17/ms_28/',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define shape of heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABA_directory = '/home/zachpen87/clearmap/AtlasDocs/Horizontal'\n",
    "ABA_ref = 'ABA_25um_reference__1_2_3__slice_None_None_None__slice_None_None_None__slice_None_None_None__.tif'\n",
    "ref = skimage.io.imread(os.path.join(ABA_directory, ABA_ref))\n",
    "htmp_shape = ref.shape\n",
    "del ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dir_list:\n",
    "\n",
    "    # load coordinate files and slice info\n",
    "    hdf5_file   = os.path.join(directory,'data.hdf5')\n",
    "    coords_file = os.path.join(directory,'coords.npy')\n",
    "    coords = np.load(coords_file)\n",
    "    slc = (slice(None,None), slice(coords[0,0],coords[0,1]), slice(coords[1,0],coords[1,1]))\n",
    "    \n",
    "    \n",
    "    # load workspace\n",
    "    ws = wsp.Workspace('CellMap', directory=directory);\n",
    "    ws.update(raw='fos.npy', autofluorescence='auto.npy')\n",
    "    resources_directory = settings.resources_path\n",
    "    \n",
    "    \n",
    "    # print hdf5 dataset, workspace, and coordinate info\n",
    "    with h5py.File(hdf5_file,'a') as f:\n",
    "        print('hdf5_file datasets: {x}'.format(x=list(f.keys())))\n",
    "        print('hdf5_file shape: {x}\\n'.format(x=f['fos'].shape))\n",
    "    print(ws.info())\n",
    "    print('slice coordinates: y={y}, x={x}'.format(y=coords[0],x=coords[1]))\n",
    "    \n",
    "    \n",
    "    #smooth image\n",
    "    H5img.hdf5_filter(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_in = 'fos',\n",
    "        dset_out = 'smooth',\n",
    "        filt = 'median', ksize  = (3,3,3),\n",
    "        slc = slc)\n",
    "    \n",
    "    \n",
    "    #remove background\n",
    "    H5img.hdf5_filter(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_in = 'smooth',\n",
    "        dset_out = 'bg',\n",
    "        filt = 'opening', ksize  = (5,5,5))\n",
    "    H5img.hdf5_bgsubtract(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_img = 'smooth',\n",
    "        dset_bg = 'bg',\n",
    "        dset_out = 'bg_rmv')\n",
    "    \n",
    "    \n",
    "    #threshold background subtracted image\n",
    "    threshold = 8\n",
    "    with h5py.File(hdf5_file,'a') as f:\n",
    "        image = da.from_array(\n",
    "                f['bg_rmv'],\n",
    "                chunks = (400,400,400)) \n",
    "        image[image<threshold] = 0\n",
    "        image.to_hdf5(hdf5_file,('/'+'thresh'))\n",
    "        \n",
    "    \n",
    "    #calculate distance transform\n",
    "    H5img.hdf5_filter(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_in = 'thresh',\n",
    "        dset_out = 'dist',\n",
    "        filt = 'distance_transform')\n",
    "    \n",
    "    \n",
    "    #define local maxima of distance transform\n",
    "    H5img.hdf5_filter(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_in = 'dist',\n",
    "        dset_out = 'local_max',\n",
    "        filt = 'local_max',\n",
    "        ksize = (10,10,10))\n",
    "        \n",
    "    \n",
    "    #label continuous local maxima\n",
    "    H5img.label(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_in = 'local_max',\n",
    "        dset_out = 'lbls',\n",
    "        min_size = None, max_size=500,\n",
    "        chunk_dimension = 1,\n",
    "        chunk_size = 350,\n",
    "        chunk_overlap = 25)\n",
    "   \n",
    "\n",
    "    #find centroids and save\n",
    "    centroids = H5img.find_centroids(\n",
    "        hdf5_file = hdf5_file,\n",
    "        dset_lbls = 'lbls',\n",
    "        dset_wts = 'bg_rmv',\n",
    "        chunk_dimension = 1,\n",
    "        chunk_size = 400,\n",
    "        chunk_overlap = 25)\n",
    "    with h5py.File(hdf5_file,'a') as f:\n",
    "        centroids = centroids.astype('int')\n",
    "        if 'centroids/original' in f.keys():\n",
    "            del f['centroids/original']\n",
    "        f.create_dataset('centroids/original', data=centroids)\n",
    "        \n",
    "   \n",
    "    #transform centroids and get labels\n",
    "    with h5py.File(hdf5_file,'a') as f:\n",
    "        centroids = f['centroids/original'][:]\n",
    "        input_shape = f['bg_rmv'].shape\n",
    "\n",
    "        coordinates = res.resample_points(\n",
    "                          np.flip(centroids,axis=1), sink=None, orientation=None, \n",
    "                          source_shape = tuple(np.flip(input_shape)), \n",
    "                          sink_shape = io.shape(ws.filename('resampled')));\n",
    "\n",
    "        coordinates = elx.transform_points(\n",
    "                          coordinates, sink=None, \n",
    "                          transform_directory=ws.filename('resampled_to_auto'), \n",
    "                          binary=True, indices=False);\n",
    "\n",
    "        coordinates = elx.transform_points(\n",
    "                          coordinates, sink=None, \n",
    "                          transform_directory=ws.filename('auto_to_reference'),\n",
    "                          binary=True, indices=False);\n",
    "        \n",
    "        labels = ano.label_points(\n",
    "            points =  coordinates,\n",
    "            annotation_file = '/home/zachpen87/clearmap/AtlasDocs/Horizontal/ABA_25um_annotation.tif',\n",
    "            key = 'id')\n",
    "\n",
    "        coordinates = np.flip(coordinates, axis=1)\n",
    "        if 'centroids/transformed' in f.keys():\n",
    "            del f['centroids/transformed']\n",
    "        if 'centroids/labels' in f.keys():\n",
    "            del f['centroids/labels']\n",
    "        f.create_dataset('centroids/transformed', data=coordinates)\n",
    "        f.create_dataset('centroids/labels', data=labels)\n",
    "    \n",
    "    \n",
    "    #create heatmap\n",
    "    with h5py.File(hdf5_file,'a') as f:\n",
    "        heatmap = np.zeros(htmp_shape)\n",
    "        for x in coordinates.astype('int'):\n",
    "            try:\n",
    "                heatmap[x[0],x[1],x[2]] += 1\n",
    "            except:\n",
    "                pass\n",
    "        heatmap = H5img.array_filter(heatmap,filt='gaussian',ksize=(2,2,2))\n",
    "        if 'heatmap' in f.keys():\n",
    "            del f['heatmap']\n",
    "        f.create_dataset('heatmap', data = heatmap)\n",
    "        \n",
    "    \n",
    "    # delete intermediate files\n",
    "    temp_file = os.path.join(directory,'data_temp.hdf5')\n",
    "    os.rename(hdf5_file, temp_file)\n",
    "    with h5py.File(temp_file,'r') as tempf, h5py.File(hdf5_file,'w') as f:\n",
    "        for key in ['fos','auto','bg_rmv','heatmap','centroids/original','centroids/transformed']:\n",
    "            print('writing: {key}'.format(key=key))\n",
    "            f.create_dataset(key, data=tempf[key][:], compression='lzf')\n",
    "    os.remove(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearmap2",
   "language": "python",
   "name": "clearmap2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
