{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['DISPLAY'] = ':999'\n",
    "sys.path.append('/home/zachpen87/clearmap/ClearMap2/')\n",
    "\n",
    "import h5py\n",
    "import holoviews as hv\n",
    "import dask.array as da\n",
    "import scipy.ndimage as ndimage\n",
    "import skimage\n",
    "from ClearMap.Environment import * \n",
    "import ClearMap.ImageProcessing.H5 as H5img\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory           = '/home/zachpen87/clearmap/data/SEFL17/ms_24/' \n",
    "hdf5_file           = os.path.join(directory,'data.hdf5')\n",
    "coords_file         = os.path.join(directory,'coords.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ClearMap2 Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wsp.Workspace('CellMap', directory=directory);\n",
    "ws.update(raw='fos.npy', autofluorescence='auto.npy')\n",
    "resources_directory = settings.resources_path\n",
    "\n",
    "with h5py.File(hdf5_file,'a') as f:\n",
    "    print('hdf5_file datasets: {x}'.format(x=list(f.keys())))\n",
    "    print('hdf5_file shape: {x}\\n'.format(x=f['fos'].shape))\n",
    "print(ws.info())\n",
    "\n",
    "coords = np.load(coords_file)\n",
    "print('slice coordinates: y={y}, x={x}'.format(y=coords[0],x=coords[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%output size=80\n",
    "test_data={}\n",
    "\n",
    "with h5py.File(os.path.join(directory,'data.hdf5'),'r') as f:\n",
    "    print(f['fos'].shape)\n",
    "    test_data['raw'] = f['fos'][900:930,1300:1800,300:800]\n",
    "    \n",
    "    \n",
    "#smooth with median filter\n",
    "#as this filter is to remove high frequency, granular noise, ksize of (3,3,3) is often good\n",
    "test_data['mfilter'] = H5img.array_filter(\n",
    "    test_data['raw'], \n",
    "    filt='median', \n",
    "    ksize=(3,3,3))\n",
    "\n",
    "\n",
    "#estimate background with morphological opening\n",
    "#kernel size should be at least diameter of larger cells in all dimensions\n",
    "test_data['bg']  = H5img.array_filter(\n",
    "    test_data['mfilter'],\n",
    "    filt='opening', \n",
    "    ksize=(5,5,5))\n",
    "\n",
    "\n",
    "#remove background from median filtered iamge\n",
    "test_data['bg_rmv'] = test_data['mfilter'] - test_data['bg']\n",
    "\n",
    "\n",
    "#threshold background subtracted image to prep for subsequent steps\n",
    "t = 8\n",
    "print('threshold: {t}'.format(t=t))\n",
    "test_data['thresh'] = test_data['bg_rmv'].copy()\n",
    "test_data['thresh'][test_data['bg_rmv']<t] = 0\n",
    "\n",
    "\n",
    "#calculate distance transform\n",
    "test_data['dist'] = ndimage.distance_transform_cdt(test_data['thresh'])\n",
    "\n",
    "\n",
    "#find local max of distance transform\n",
    "test_data['lmax'] = H5img.array_filter(\n",
    "    test_data['dist'], \n",
    "    filt='local_max',\n",
    "    ksize=(10,10,10))\n",
    "\n",
    "\n",
    "#label objects and apply size restriction\n",
    "test_data['lbls'],mx = ndimage.label(test_data['lmax'], structure=np.ones((3,3,3)))\n",
    "test_data['lbls'] = H5img.droplbls_arr(test_data['lbls'], min_size = None, max_size=300)\n",
    "\n",
    "\n",
    "#find centroids\n",
    "centroids = ndimage.measurements.center_of_mass(\n",
    "    test_data['bg_rmv'], \n",
    "    labels = test_data['lbls'], \n",
    "    index = np.unique(test_data['lbls'])[np.where(np.unique(test_data['lbls'])!=0)])\n",
    "centroids = np.array([list(ctr) for ctr in centroids]).astype('int')\n",
    "print('objects found: {x}'.format(x=len(centroids)))\n",
    "\n",
    "\n",
    "#create array representing centers\n",
    "test_data['ctrs'] = np.zeros(test_data['raw'].shape)\n",
    "test_data['ctrs'][tuple(centroids.T)]=1\n",
    "test_data['ctrs'] = H5img.array_filter(test_data['ctrs'], filt='dilation',ksize=(3,3,3))\n",
    "\n",
    "\n",
    "i=2\n",
    "p='h'\n",
    "raw = jvis.gen_hmap(img=test_data['raw'],plane=p,title='raw',inter=i,tools=['hover'])\n",
    "bg = jvis.gen_hmap(img=test_data['bg'],plane=p,title='bg',inter=i,tools=['hover'])\n",
    "sig = jvis.gen_hmap(img=test_data['bg_rmv'],plane=p,title='bg removed',inter=i,cmap='viridis',tools=['hover'])\n",
    "thresh = jvis.gen_hmap(img=test_data['thresh'],plane=p,title='thresh',inter=i,cmap='viridis',tools=['hover'])\n",
    "ctrs = jvis.gen_hmap(img=test_data['ctrs'],plane=p,title='centers',inter=i,cmap='Reds',alpha=.6,tools=['hover'])\n",
    "\n",
    "#(raw + bg + sig + (thresh*ctrs).opts(title='centroids')).cols(2)\n",
    "(raw + bg + sig + thresh).opts(title='centroids').cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Processing Pipeline for Single 3d Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cropping coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slc = (slice(None,None), slice(coords[0,0],coords[0,1]), slice(coords[1,0],coords[1,1]))\n",
    "slc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = (400,400,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth image with median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H5img.hdf5_filter(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_in = 'fos',\n",
    "    dset_out = 'smooth',\n",
    "    filt = 'median', ksize  = (3,3,3),\n",
    "    chunksize = chunksize,\n",
    "    slc = slc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate background with morphological opening and subtract from smoothed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H5img.hdf5_filter(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_in = 'smooth',\n",
    "    dset_out = 'bg',\n",
    "    filt = 'opening', ksize  = (5,5,5),\n",
    "    chunksize = chunksize)\n",
    "\n",
    "H5img.hdf5_bgsubtract(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_img = 'smooth',\n",
    "    dset_bg = 'bg',\n",
    "    dset_out = 'bg_rmv',\n",
    "    chunksize = chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold background subtracted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "threshold = 8\n",
    "with h5py.File(hdf5_file,'a') as f:\n",
    "    image = da.from_array(\n",
    "            f['bg_rmv'],\n",
    "            chunks = chunksize) \n",
    "    image[image<threshold] = 0\n",
    "    image.to_hdf5(hdf5_file,('/'+'thresh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H5img.hdf5_filter(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_in = 'thresh',\n",
    "    dset_out = 'dist',\n",
    "    filt = 'distance_transform',\n",
    "    chunksize = chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define local maxima of distance transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H5img.hdf5_filter(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_in = 'dist',\n",
    "    dset_out = 'local_max',\n",
    "    filt = 'local_max',\n",
    "    ksize = (10,10,10),\n",
    "    chunksize = chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label contiguous local maxima as cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "H5img.label(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_in = 'local_max',\n",
    "    dset_out = 'lbls',\n",
    "    min_size = None, max_size=500,\n",
    "    chunk_dimension = 1,\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "centroids = H5img.find_centroids(\n",
    "    hdf5_file = hdf5_file,\n",
    "    dset_lbls = 'lbls',\n",
    "    dset_wts = 'bg_rmv',\n",
    "    chunk_dimension = 1,\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap = 50)\n",
    "with h5py.File(hdf5_file,'a') as f:\n",
    "    centroids = centroids.astype('int')\n",
    "    if 'centroids/original' in f.keys():\n",
    "        del f['centroids/original']\n",
    "    f.create_dataset('centroids/original', data=centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform centroids to ABA coordinate plane and define annotation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_file,'a') as f:\n",
    "    centroids = f['centroids/original'][:]\n",
    "    input_shape = f['bg_rmv'].shape\n",
    "\n",
    "    coordinates = res.resample_points(\n",
    "                      np.flip(centroids,axis=1), sink=None, orientation=None, \n",
    "                      source_shape = tuple(np.flip(input_shape)), \n",
    "                      sink_shape = io.shape(ws.filename('resampled')));\n",
    "\n",
    "    coordinates = elx.transform_points(\n",
    "                      coordinates, sink=None, \n",
    "                      transform_directory=ws.filename('resampled_to_auto'), \n",
    "                      binary=True, indices=False);\n",
    "\n",
    "    coordinates = elx.transform_points(\n",
    "                      coordinates, sink=None, \n",
    "                      transform_directory=ws.filename('auto_to_reference'),\n",
    "                      binary=True, indices=False);\n",
    "    \n",
    "    labels = ano.label_points(\n",
    "            points =  coordinates,\n",
    "            annotation_file = '/home/zachpen87/clearmap/AtlasDocs/Horizontal/ABA_25um_annotation.tif',\n",
    "            key = 'id')\n",
    "    \n",
    "    coordinates = np.flip(coordinates, axis=1)\n",
    "    if 'centroids/transformed' in f.keys():\n",
    "        del f['centroids/transformed']\n",
    "    if 'centroids/labels' in f.keys():\n",
    "        del f['centroids/labels']\n",
    "    f.create_dataset('centroids/transformed', data=coordinates)\n",
    "    f.create_dataset('centroids/labels', data=labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABA_directory = '/home/zachpen87/clearmap/AtlasDocs/Horizontal'\n",
    "ABA_ref = 'ABA_25um_reference__1_2_3__slice_None_None_None__slice_None_None_None__slice_None_None_None__.tif'\n",
    "ref = skimage.io.imread(os.path.join(ABA_directory, ABA_ref))\n",
    "\n",
    "with h5py.File(hdf5_file,'a') as f:\n",
    "    heatmap = np.zeros(ref.shape)\n",
    "    coordinates = f['centroids/transformed'][:]\n",
    "    for x in coordinates.astype('int'):\n",
    "        try:\n",
    "            heatmap[x[0],x[1],x[2]] += 1\n",
    "        except:\n",
    "            pass\n",
    "    heatmap = H5img.array_filter(heatmap,filt='gaussian',ksize=(2,2,2))\n",
    "    if 'heatmap' in f.keys():\n",
    "        del f['heatmap']\n",
    "    f.create_dataset('heatmap', data = heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%output size = 150\n",
    "\n",
    "interval = 20\n",
    "plane = 'c'\n",
    "\n",
    "with h5py.File(hdf5_file,'r') as f:\n",
    "    ABA_directory = '/home/zachpen87/clearmap/AtlasDocs/Horizontal'\n",
    "    ABA_ref = 'ABA_25um_reference__1_2_3__slice_None_None_None__slice_None_None_None__slice_None_None_None__.tif'\n",
    "    ref = skimage.io.imread(os.path.join(ABA_directory, ABA_ref))\n",
    "    ref_i = jvis.gen_hmap(ref,plane=plane,title='Allen Brain Atlas',inter=interval)\n",
    "    hmap_i = jvis.gen_hmap(f['heatmap'][:],plane=plane,title='Cells',inter=interval,cmap='inferno',lims=(0,.2),alpha=.6,tools=['hover'])\n",
    "\n",
    "(ref_i*hmap_i).opts(title='Cells mapped to Allen Brain Atlas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete intermediate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = os.path.join(directory,'data_temp.hdf5')\n",
    "os.rename(hdf5_file, temp_file)\n",
    "with h5py.File(temp_file,'r') as tempf, h5py.File(hdf5_file,'w') as f:\n",
    "    for key in ['fos','auto','bg_rmv','heatmap','centroids/original','centroids/transformed']:\n",
    "        print('writing: {key}'.format(key=key))\n",
    "        f.create_dataset(key, data=tempf[key][:], compression='lzf')\n",
    "os.remove(temp_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearmap2",
   "language": "python",
   "name": "clearmap2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
